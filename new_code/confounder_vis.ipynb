{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/elissali/Documents/GitHub/cs231n-adni/new_code\n"
     ]
    }
   ],
   "source": [
    "% cd ~/Documents/GitHub/cs231n-adni/new_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import utils\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.model_selection import train_test_split\n",
    "import multiprocessing\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1])\n"
     ]
    }
   ],
   "source": [
    "import data, model, interpretation, utils, vis_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load(\"train_aug.npy\")\n",
    "val_data = np.load(\"val_aug.npy\")\n",
    "test_data = np.load(\"test_aug.npy\")\n",
    "train_label = np.load(\"train_label_aug.npy\")\n",
    "val_label = np.load(\"val_label_aug.npy\")\n",
    "test_label = np.load(\"test_label_aug.npy\")\n",
    "\n",
    "train_data = np.reshape(train_data, (2048, 1, 64, 64, 64))\n",
    "val_data = np.reshape(val_data, (512, 1, 64, 64, 64))\n",
    "test_data = np.reshape(test_data, (512, 1, 64, 64, 64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 64, 64, 64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.reshape(train_data, (2048, 1, 64, 64, 64))      # want channels first!\n",
    "test_data = np.reshape(test_data, (512, 1, 64, 64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "neg_ex = torch.squeeze(torch.from_numpy(test_data[11]))\n",
    "pos_ex = torch.squeeze(torch.from_numpy(test_data[500]))\n",
    "\n",
    "print(pos_ex.shape)\n",
    "# vis_utils.plot_slices(neg_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = model.SingleTimestep3DCNN(in_num_ch=1, img_size=(64,64,64), inter_num_ch=16, fc_num_ch=16,\n",
    "                                conv_act='relu', fc_act='tanh').to(torch.device('cpu'))\n",
    "\n",
    "# net.load_state_dict(torch.load('../ckpt/2020_5_5_21_44/model_best.pth.tar')['model'])\n",
    "net.load_state_dict(torch.load('../ckpt/2020_5_18_16_42/epoch031.pth.tar')['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64, 64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[2000][0].shape\n",
    "train_data[0][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confounder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 64, 64, 64])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex = torch.Tensor([test_data[0]])\n",
    "ex.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16, 4, 4, 4])\n",
      "torch.Size([1, 1024])\n"
     ]
    }
   ],
   "source": [
    "features = net.feature_extractor(ex)\n",
    "print(features.shape)\n",
    "flat_features = features.view(ex.shape[0], -1)\n",
    "print(flat_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=32, out_features=1, bias=True)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.fc3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://discuss.pytorch.org/t/insert-new-layer-in-the-middle-of-a-pre-trained-model/12414/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Confounder3DCNN(nn.Module):\n",
    "    def __init__(self, in_num_ch=1, img_size=(32,64,64), inter_num_ch=16, fc_num_ch=16,\n",
    "                conv_act='relu', fc_act='tanh'):\n",
    "        super(Confounder3DCNN, self).__init__()\n",
    "\n",
    "        self.feature_extractor = net.feature_extractor # use feature extractor from existing model\n",
    "        num_feat = int(inter_num_ch * (img_size[0]*img_size[1]*img_size[2]) / ((2**4)**3))\n",
    "\n",
    "        num_output = 1\n",
    "        self.num_cls = 2\n",
    "\n",
    "        self.fc1 = net.fc1    # use fc1 from existing model\n",
    "        self.fc2 = net.fc1    # use fc2 from existing model\n",
    "        self.fc3 = net.fc3    # use fc3 from existing model\n",
    "\n",
    "        self.init_model()\n",
    "\n",
    "    def init_model(self):\n",
    "        for layer in [self.fc1, self.fc2, self.fc3]:\n",
    "            for name, weight in layer.named_parameters():\n",
    "                if 'weight' in name:\n",
    "                    nn.init.xavier_normal_(weight)\n",
    "                if 'bias' in name:\n",
    "                    nn.init.constant_(weight, 0.0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv4 = self.feature_extractor(x)\n",
    "        conv4_flatten = conv4.view(x.shape[0], -1)\n",
    "        conv4_mask = BinaryMask(conv4_flatten, mask, pre_feature)   # apply binary_mask after conv4_flatten\n",
    "        fc1 = self.fc1(conv4_mask)\n",
    "        fc2 = self.fc2(fc1)\n",
    "        output = self.fc3(fc2)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a dummy layer\n",
    "class BinaryMask(Layer):\n",
    "\n",
    "    def __init__(self, output_dim, mask, pre_feature, **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        self.mask = mask\n",
    "        self.pre_feature = pre_feature\n",
    "        \n",
    "        super(BinaryMask, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.mask_tensor = K.variable(self.mask)\n",
    "        self.pre_feature = K.variable(self.pre_feature)\n",
    "        \n",
    "        super(BinaryMask, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, x):\n",
    "        return x * self.mask_tensor + self.pre_feature\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think what's happening here is:\n",
    "- BinaryMask takes the original layer, then masks it, then adds back the original values (of the stuff it zeroed out?)\n",
    "- The idea being that you \"fix\" the value of the confounded features/don't backprop them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
